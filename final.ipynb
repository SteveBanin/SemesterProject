{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpingWindow:\n",
    "    \n",
    "    \n",
    "    def __init__(self, size, overlap, strict_size=True):\n",
    "        if (\n",
    "            not isinstance(size, int) or\n",
    "            not isinstance(overlap, int) or\n",
    "            not isinstance(strict_size, bool) or\n",
    "            overlap >= size\n",
    "        ):\n",
    "            title = \"ERROR: Wrong values in JumpingWindow constructor.\"\n",
    "            description = \"Expecting: size(int), overlap(int), strict_size(bool), AND overlap < size\"\n",
    "            provided = \"size({}), overlap({}), strict_size({}), overlap < size? {}\".format(\n",
    "                    type(size),\n",
    "                    type(overlap),\n",
    "                    type(strict_size),\n",
    "                    overlap < size\n",
    "                )\n",
    "            raise Exception(title + \"\\n\" + description + \"\\n\" + provided)\n",
    "        self.windows = []\n",
    "        self.entries = []\n",
    "        self.size = size\n",
    "        self.overlap = overlap\n",
    "        self.strict_size = strict_size\n",
    "        self.transformed = False\n",
    "\n",
    "\n",
    "    def add(self, element):\n",
    "        if self.transformed:\n",
    "            raise Exception(\"Cannot add the elements to the window, once it has been transformed!\")\n",
    "        self.entries.append(element)\n",
    "\n",
    "\n",
    "    def transform_entries_to_windows(self):\n",
    "        for i in range(0, len(self.entries), self.size-self.overlap):\n",
    "            window = self.entries[i:i+self.size]\n",
    "            if (self.strict_size and (len(window) != self.size)):\n",
    "                continue\n",
    "            self.windows.append(window)\n",
    "        self.transformed = True\n",
    "    \n",
    "    \n",
    "    def getWindow(self, window_number):\n",
    "        return windows[window_number]\n",
    "    \n",
    "    \n",
    "    def getAllWindows(self):\n",
    "        return self.windows[:]\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        result = \"\\n---------- Jumping Window ----------\\n\"\n",
    "        for i in range(len(self.windows)):\n",
    "            result = result + \"Window {}:\\t{}\\n\".format(i, self.windows[i])\n",
    "        result = result + \"------------------------------------\\n\"\n",
    "        return result\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapeMatrix(one_dimensional_list, num_rows, num_cols):\n",
    "    if (num_rows * num_cols != len(one_dimensional_list)):\n",
    "        # not possible to transform the values\n",
    "        return None\n",
    "    else:\n",
    "        matrix = []\n",
    "        for i in range(num_rows):\n",
    "            row = []\n",
    "            for j in range(num_cols):\n",
    "                row.append(j)\n",
    "            matrix.append(row)\n",
    "        return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValuesFromFile(filename):\n",
    "    values = []\n",
    "\n",
    "    f = open(\"merged_test_0026.csv\", \"r\")\n",
    "    line = f.readline() # col titles\n",
    "    line = f.readline() # first row\n",
    "    while line:\n",
    "        values.append(np.float32(line.split(\",\")[0]))\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down into overlapping jumping windows\n",
    "def createJumpingWindows(values):\n",
    "    jws = JumpingWindow(30, 5)\n",
    "    for value in values:\n",
    "        jws.add(value)\n",
    "    jws.transform_entries_to_windows()\n",
    "    return jws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I create default graph \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for my stacked autoencoders\n",
    "num_inputs = 30\n",
    "neurons_hid1 = 20\n",
    "neurons_hid2 = 10\n",
    "neurons_hid3 = neurons_hid1\n",
    "num_output = num_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fun = tf.nn.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I begin everything I need for the session of my Graph\n",
    "X = tf.placeholder(tf.float32,shape=[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now here I set my weight: where I am trying to achieve the weight of the tensors\n",
    "initializer = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I create my weight variables\n",
    "\n",
    "w1 = tf.Variable(initializer([num_inputs,neurons_hid1]),dtype=tf.float32)\n",
    "w2 = tf.Variable(initializer([neurons_hid1,neurons_hid2]),dtype=tf.float32)\n",
    "w3 = tf.Variable(initializer([neurons_hid2,neurons_hid3]),dtype=tf.float32)\n",
    "w4 = tf.Variable(initializer([neurons_hid3,num_output]),dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I create my bias\n",
    "b1 = tf.Variable(tf.zeros(neurons_hid1))\n",
    "b2 = tf.Variable(tf.zeros(neurons_hid2))\n",
    "b3 = tf.Variable(tf.zeros(neurons_hid3))\n",
    "b4 = tf.Variable(tf.zeros(num_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = tf.nn.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I create my hidden layers\n",
    "hid_layer1 = activation_func(tf.matmul(X,w1)+b1)\n",
    "hid_layer2 = activation_func(tf.matmul(hid_layer1,w2)+b2) \n",
    "hid_layer3 = activation_func(tf.matmul(hid_layer2,w3)+b3) \n",
    "output_layer = activation_func(tf.matmul(hid_layer3,w4)+b4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I define my cost functions(loss)\n",
    "loss = tf.reduce_mean(tf.squared_difference(output_layer, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I define my optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I define my trianing operation attempting to minimize the loss function\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Learning file: merged_test_0055.csv =====\n",
      "\tEpoch: 0\tLoss: 269.08740234375\n",
      "\tEpoch: 1\tLoss: 267.8641052246094\n",
      "\tEpoch: 2\tLoss: 266.6685485839844\n",
      "\tEpoch: 3\tLoss: 265.5252990722656\n",
      "\tEpoch: 4\tLoss: 264.4192199707031\n",
      "\tEpoch: 5\tLoss: 263.3459777832031\n",
      "\tEpoch: 6\tLoss: 262.37652587890625\n",
      "\tEpoch: 7\tLoss: 261.51922607421875\n",
      "\tEpoch: 8\tLoss: 260.7865905761719\n",
      "\tEpoch: 9\tLoss: 260.1778869628906\n",
      "\tEpoch: 10\tLoss: 259.6820068359375\n",
      "\tEpoch: 11\tLoss: 259.2823486328125\n",
      "\tEpoch: 12\tLoss: 258.9541931152344\n",
      "\tEpoch: 13\tLoss: 258.6930847167969\n",
      "\tEpoch: 14\tLoss: 258.48211669921875\n",
      "\tEpoch: 15\tLoss: 258.3103332519531\n",
      "\tEpoch: 16\tLoss: 258.1692199707031\n",
      "\tEpoch: 17\tLoss: 258.0523376464844\n",
      "\tEpoch: 18\tLoss: 257.9547424316406\n",
      "\tEpoch: 19\tLoss: 257.8725891113281\n",
      "Completed file: merged_test_0055.csv\tTraining Losses: [269.087..257.873]\n",
      "===== Learning file: merged_test_0033.csv =====\n",
      "\tEpoch: 0\tLoss: 257.8028564453125\n",
      "\tEpoch: 1\tLoss: 257.74322509765625\n",
      "\tEpoch: 2\tLoss: 257.69183349609375\n",
      "\tEpoch: 3\tLoss: 257.6472473144531\n",
      "\tEpoch: 4\tLoss: 257.6083068847656\n",
      "\tEpoch: 5\tLoss: 257.57403564453125\n",
      "\tEpoch: 6\tLoss: 257.543701171875\n",
      "\tEpoch: 7\tLoss: 257.5167236328125\n",
      "\tEpoch: 8\tLoss: 257.4925842285156\n",
      "\tEpoch: 9\tLoss: 257.4709167480469\n",
      "\tEpoch: 10\tLoss: 257.45135498046875\n",
      "\tEpoch: 11\tLoss: 257.43365478515625\n",
      "\tEpoch: 12\tLoss: 257.4175109863281\n",
      "\tEpoch: 13\tLoss: 257.40277099609375\n",
      "\tEpoch: 14\tLoss: 257.3892822265625\n",
      "\tEpoch: 15\tLoss: 257.37689208984375\n",
      "\tEpoch: 16\tLoss: 257.3654479980469\n",
      "\tEpoch: 17\tLoss: 257.3548889160156\n",
      "\tEpoch: 18\tLoss: 257.3450622558594\n",
      "\tEpoch: 19\tLoss: 257.3359680175781\n",
      "Completed file: merged_test_0033.csv\tTraining Losses: [257.803..257.336]\n",
      "===== Learning file: merged_test_0041.csv =====\n",
      "\tEpoch: 0\tLoss: 257.3275146484375\n",
      "\tEpoch: 1\tLoss: 257.319580078125\n",
      "\tEpoch: 2\tLoss: 257.31219482421875\n",
      "\tEpoch: 3\tLoss: 257.3052673339844\n",
      "\tEpoch: 4\tLoss: 257.2987976074219\n",
      "\tEpoch: 5\tLoss: 257.2926940917969\n",
      "\tEpoch: 6\tLoss: 257.2869567871094\n",
      "\tEpoch: 7\tLoss: 257.28155517578125\n",
      "\tEpoch: 8\tLoss: 257.27642822265625\n",
      "\tEpoch: 9\tLoss: 257.2716064453125\n",
      "\tEpoch: 10\tLoss: 257.26702880859375\n",
      "\tEpoch: 11\tLoss: 257.2626953125\n",
      "\tEpoch: 12\tLoss: 257.2585754394531\n",
      "\tEpoch: 13\tLoss: 257.2546691894531\n",
      "\tEpoch: 14\tLoss: 257.2509460449219\n",
      "\tEpoch: 15\tLoss: 257.2474060058594\n",
      "\tEpoch: 16\tLoss: 257.2440490722656\n",
      "\tEpoch: 17\tLoss: 257.2408447265625\n",
      "\tEpoch: 18\tLoss: 257.2377624511719\n",
      "\tEpoch: 19\tLoss: 257.2348327636719\n",
      "Completed file: merged_test_0041.csv\tTraining Losses: [257.328..257.235]\n",
      "===== Learning file: merged_test_0043.csv =====\n",
      "\tEpoch: 0\tLoss: 257.2320251464844\n",
      "\tEpoch: 1\tLoss: 257.2293395996094\n",
      "\tEpoch: 2\tLoss: 257.2267761230469\n",
      "\tEpoch: 3\tLoss: 257.22430419921875\n",
      "\tEpoch: 4\tLoss: 257.2219543457031\n",
      "\tEpoch: 5\tLoss: 257.2196960449219\n",
      "\tEpoch: 6\tLoss: 257.2174987792969\n",
      "\tEpoch: 7\tLoss: 257.21539306640625\n",
      "\tEpoch: 8\tLoss: 257.2134094238281\n",
      "\tEpoch: 9\tLoss: 257.21148681640625\n",
      "\tEpoch: 10\tLoss: 257.2095947265625\n",
      "\tEpoch: 11\tLoss: 257.2077941894531\n",
      "\tEpoch: 12\tLoss: 257.2060546875\n",
      "\tEpoch: 13\tLoss: 257.20440673828125\n",
      "\tEpoch: 14\tLoss: 257.2027893066406\n",
      "\tEpoch: 15\tLoss: 257.20123291015625\n",
      "\tEpoch: 16\tLoss: 257.1997375488281\n",
      "\tEpoch: 17\tLoss: 257.1982727050781\n",
      "\tEpoch: 18\tLoss: 257.1968688964844\n",
      "\tEpoch: 19\tLoss: 257.19549560546875\n",
      "Completed file: merged_test_0043.csv\tTraining Losses: [257.232..257.195]\n",
      "===== Learning file: merged_test_0063.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1941833496094\n",
      "\tEpoch: 1\tLoss: 257.19293212890625\n",
      "\tEpoch: 2\tLoss: 257.19171142578125\n",
      "\tEpoch: 3\tLoss: 257.19049072265625\n",
      "\tEpoch: 4\tLoss: 257.1893310546875\n",
      "\tEpoch: 5\tLoss: 257.1882019042969\n",
      "\tEpoch: 6\tLoss: 257.1871337890625\n",
      "\tEpoch: 7\tLoss: 257.1860656738281\n",
      "\tEpoch: 8\tLoss: 257.1850280761719\n",
      "\tEpoch: 9\tLoss: 257.1840515136719\n",
      "\tEpoch: 10\tLoss: 257.1830749511719\n",
      "\tEpoch: 11\tLoss: 257.18212890625\n",
      "\tEpoch: 12\tLoss: 257.18121337890625\n",
      "\tEpoch: 13\tLoss: 257.1803283691406\n",
      "\tEpoch: 14\tLoss: 257.1794738769531\n",
      "\tEpoch: 15\tLoss: 257.17864990234375\n",
      "\tEpoch: 16\tLoss: 257.1778259277344\n",
      "\tEpoch: 17\tLoss: 257.17706298828125\n",
      "\tEpoch: 18\tLoss: 257.17626953125\n",
      "\tEpoch: 19\tLoss: 257.1755065917969\n",
      "Completed file: merged_test_0063.csv\tTraining Losses: [257.194..257.176]\n",
      "===== Learning file: merged_test_0038.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1747741699219\n",
      "\tEpoch: 1\tLoss: 257.1740417480469\n",
      "\tEpoch: 2\tLoss: 257.1733703613281\n",
      "\tEpoch: 3\tLoss: 257.1726989746094\n",
      "\tEpoch: 4\tLoss: 257.1720275878906\n",
      "\tEpoch: 5\tLoss: 257.1713562011719\n",
      "\tEpoch: 6\tLoss: 257.1707458496094\n",
      "\tEpoch: 7\tLoss: 257.17010498046875\n",
      "\tEpoch: 8\tLoss: 257.1695251464844\n",
      "\tEpoch: 9\tLoss: 257.1689453125\n",
      "\tEpoch: 10\tLoss: 257.1683654785156\n",
      "\tEpoch: 11\tLoss: 257.1678161621094\n",
      "\tEpoch: 12\tLoss: 257.1672668457031\n",
      "\tEpoch: 13\tLoss: 257.1667175292969\n",
      "\tEpoch: 14\tLoss: 257.16619873046875\n",
      "\tEpoch: 15\tLoss: 257.1656799316406\n",
      "\tEpoch: 16\tLoss: 257.1651916503906\n",
      "\tEpoch: 17\tLoss: 257.1647033691406\n",
      "\tEpoch: 18\tLoss: 257.1642150878906\n",
      "\tEpoch: 19\tLoss: 257.16375732421875\n",
      "Completed file: merged_test_0038.csv\tTraining Losses: [257.175..257.164]\n",
      "===== Learning file: merged_test_0049.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1632995605469\n",
      "\tEpoch: 1\tLoss: 257.1628723144531\n",
      "\tEpoch: 2\tLoss: 257.16241455078125\n",
      "\tEpoch: 3\tLoss: 257.1619873046875\n",
      "\tEpoch: 4\tLoss: 257.16156005859375\n",
      "\tEpoch: 5\tLoss: 257.1611633300781\n",
      "\tEpoch: 6\tLoss: 257.1607360839844\n",
      "\tEpoch: 7\tLoss: 257.1603698730469\n",
      "\tEpoch: 8\tLoss: 257.15997314453125\n",
      "\tEpoch: 9\tLoss: 257.15960693359375\n",
      "\tEpoch: 10\tLoss: 257.15924072265625\n",
      "\tEpoch: 11\tLoss: 257.1588439941406\n",
      "\tEpoch: 12\tLoss: 257.15850830078125\n",
      "\tEpoch: 13\tLoss: 257.1581726074219\n",
      "\tEpoch: 14\tLoss: 257.1578063964844\n",
      "\tEpoch: 15\tLoss: 257.1575012207031\n",
      "\tEpoch: 16\tLoss: 257.15716552734375\n",
      "\tEpoch: 17\tLoss: 257.1568298339844\n",
      "\tEpoch: 18\tLoss: 257.1565246582031\n",
      "\tEpoch: 19\tLoss: 257.1562194824219\n",
      "Completed file: merged_test_0049.csv\tTraining Losses: [257.163..257.156]\n",
      "===== Learning file: merged_test_0045.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1558837890625\n",
      "\tEpoch: 1\tLoss: 257.1556091308594\n",
      "\tEpoch: 2\tLoss: 257.1553039550781\n",
      "\tEpoch: 3\tLoss: 257.1549987792969\n",
      "\tEpoch: 4\tLoss: 257.15472412109375\n",
      "\tEpoch: 5\tLoss: 257.1544494628906\n",
      "\tEpoch: 6\tLoss: 257.1542053222656\n",
      "\tEpoch: 7\tLoss: 257.1539001464844\n",
      "\tEpoch: 8\tLoss: 257.1536560058594\n",
      "\tEpoch: 9\tLoss: 257.1534118652344\n",
      "\tEpoch: 10\tLoss: 257.1531677246094\n",
      "\tEpoch: 11\tLoss: 257.15289306640625\n",
      "\tEpoch: 12\tLoss: 257.15264892578125\n",
      "\tEpoch: 13\tLoss: 257.15240478515625\n",
      "\tEpoch: 14\tLoss: 257.15216064453125\n",
      "\tEpoch: 15\tLoss: 257.15191650390625\n",
      "\tEpoch: 16\tLoss: 257.1517028808594\n",
      "\tEpoch: 17\tLoss: 257.1514892578125\n",
      "\tEpoch: 18\tLoss: 257.1512756347656\n",
      "\tEpoch: 19\tLoss: 257.1510314941406\n",
      "Completed file: merged_test_0045.csv\tTraining Losses: [257.156..257.151]\n",
      "===== Learning file: merged_test_0046.csv =====\n",
      "\tEpoch: 0\tLoss: 257.15081787109375\n",
      "\tEpoch: 1\tLoss: 257.1506042480469\n",
      "\tEpoch: 2\tLoss: 257.1504211425781\n",
      "\tEpoch: 3\tLoss: 257.15020751953125\n",
      "\tEpoch: 4\tLoss: 257.1499938964844\n",
      "\tEpoch: 5\tLoss: 257.1498107910156\n",
      "\tEpoch: 6\tLoss: 257.14959716796875\n",
      "\tEpoch: 7\tLoss: 257.1494140625\n",
      "\tEpoch: 8\tLoss: 257.1492614746094\n",
      "\tEpoch: 9\tLoss: 257.1490478515625\n",
      "\tEpoch: 10\tLoss: 257.14886474609375\n",
      "\tEpoch: 11\tLoss: 257.148681640625\n",
      "\tEpoch: 12\tLoss: 257.1485290527344\n",
      "\tEpoch: 13\tLoss: 257.1483459472656\n",
      "\tEpoch: 14\tLoss: 257.1481628417969\n",
      "\tEpoch: 15\tLoss: 257.1479797363281\n",
      "\tEpoch: 16\tLoss: 257.1478271484375\n",
      "\tEpoch: 17\tLoss: 257.14764404296875\n",
      "\tEpoch: 18\tLoss: 257.14752197265625\n",
      "\tEpoch: 19\tLoss: 257.1473388671875\n",
      "Completed file: merged_test_0046.csv\tTraining Losses: [257.151..257.147]\n",
      "===== Learning file: merged_test_0057.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1471862792969\n",
      "\tEpoch: 1\tLoss: 257.14703369140625\n",
      "\tEpoch: 2\tLoss: 257.1468811035156\n",
      "\tEpoch: 3\tLoss: 257.1467590332031\n",
      "\tEpoch: 4\tLoss: 257.1465759277344\n",
      "\tEpoch: 5\tLoss: 257.14642333984375\n",
      "\tEpoch: 6\tLoss: 257.14630126953125\n",
      "\tEpoch: 7\tLoss: 257.1461486816406\n",
      "\tEpoch: 8\tLoss: 257.1460266113281\n",
      "\tEpoch: 9\tLoss: 257.1459045410156\n",
      "\tEpoch: 10\tLoss: 257.1457214355469\n",
      "\tEpoch: 11\tLoss: 257.1455993652344\n",
      "\tEpoch: 12\tLoss: 257.1454772949219\n",
      "\tEpoch: 13\tLoss: 257.1453552246094\n",
      "\tEpoch: 14\tLoss: 257.14520263671875\n",
      "\tEpoch: 15\tLoss: 257.1451110839844\n",
      "\tEpoch: 16\tLoss: 257.14495849609375\n",
      "\tEpoch: 17\tLoss: 257.1448669433594\n",
      "\tEpoch: 18\tLoss: 257.14471435546875\n",
      "\tEpoch: 19\tLoss: 257.14459228515625\n",
      "Completed file: merged_test_0057.csv\tTraining Losses: [257.147..257.145]\n",
      "===== Learning file: merged_test_0044.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1445007324219\n",
      "\tEpoch: 1\tLoss: 257.1443786621094\n",
      "\tEpoch: 2\tLoss: 257.1442565917969\n",
      "\tEpoch: 3\tLoss: 257.1441345214844\n",
      "\tEpoch: 4\tLoss: 257.14404296875\n",
      "\tEpoch: 5\tLoss: 257.1439208984375\n",
      "\tEpoch: 6\tLoss: 257.1438293457031\n",
      "\tEpoch: 7\tLoss: 257.1437072753906\n",
      "\tEpoch: 8\tLoss: 257.14361572265625\n",
      "\tEpoch: 9\tLoss: 257.14349365234375\n",
      "\tEpoch: 10\tLoss: 257.1434020996094\n",
      "\tEpoch: 11\tLoss: 257.1432800292969\n",
      "\tEpoch: 12\tLoss: 257.1432189941406\n",
      "\tEpoch: 13\tLoss: 257.1430969238281\n",
      "\tEpoch: 14\tLoss: 257.14300537109375\n",
      "\tEpoch: 15\tLoss: 257.1429138183594\n",
      "\tEpoch: 16\tLoss: 257.1427917480469\n",
      "\tEpoch: 17\tLoss: 257.1427001953125\n",
      "\tEpoch: 18\tLoss: 257.1426086425781\n",
      "\tEpoch: 19\tLoss: 257.14251708984375\n",
      "Completed file: merged_test_0044.csv\tTraining Losses: [257.145..257.143]\n",
      "===== Learning file: merged_test_0037.csv =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch: 0\tLoss: 257.1424560546875\n",
      "\tEpoch: 1\tLoss: 257.1423645019531\n",
      "\tEpoch: 2\tLoss: 257.1422424316406\n",
      "\tEpoch: 3\tLoss: 257.1421813964844\n",
      "\tEpoch: 4\tLoss: 257.14208984375\n",
      "\tEpoch: 5\tLoss: 257.1419982910156\n",
      "\tEpoch: 6\tLoss: 257.1419372558594\n",
      "\tEpoch: 7\tLoss: 257.1418151855469\n",
      "\tEpoch: 8\tLoss: 257.1417541503906\n",
      "\tEpoch: 9\tLoss: 257.14166259765625\n",
      "\tEpoch: 10\tLoss: 257.1415710449219\n",
      "\tEpoch: 11\tLoss: 257.1415100097656\n",
      "\tEpoch: 12\tLoss: 257.1414489746094\n",
      "\tEpoch: 13\tLoss: 257.141357421875\n",
      "\tEpoch: 14\tLoss: 257.1412658691406\n",
      "\tEpoch: 15\tLoss: 257.1412048339844\n",
      "\tEpoch: 16\tLoss: 257.1411437988281\n",
      "\tEpoch: 17\tLoss: 257.14105224609375\n",
      "\tEpoch: 18\tLoss: 257.1409912109375\n",
      "\tEpoch: 19\tLoss: 257.1408996582031\n",
      "Completed file: merged_test_0037.csv\tTraining Losses: [257.142..257.141]\n",
      "===== Learning file: merged_test_0062.csv =====\n",
      "\tEpoch: 0\tLoss: 257.14080810546875\n",
      "\tEpoch: 1\tLoss: 257.1407470703125\n",
      "\tEpoch: 2\tLoss: 257.14068603515625\n",
      "\tEpoch: 3\tLoss: 257.140625\n",
      "\tEpoch: 4\tLoss: 257.14056396484375\n",
      "\tEpoch: 5\tLoss: 257.1405029296875\n",
      "\tEpoch: 6\tLoss: 257.14044189453125\n",
      "\tEpoch: 7\tLoss: 257.1403503417969\n",
      "\tEpoch: 8\tLoss: 257.1402893066406\n",
      "\tEpoch: 9\tLoss: 257.1402282714844\n",
      "\tEpoch: 10\tLoss: 257.1401672363281\n",
      "\tEpoch: 11\tLoss: 257.1401062011719\n",
      "\tEpoch: 12\tLoss: 257.1400451660156\n",
      "\tEpoch: 13\tLoss: 257.1399841308594\n",
      "\tEpoch: 14\tLoss: 257.1399230957031\n",
      "\tEpoch: 15\tLoss: 257.1398620605469\n",
      "\tEpoch: 16\tLoss: 257.1398010253906\n",
      "\tEpoch: 17\tLoss: 257.1397399902344\n",
      "\tEpoch: 18\tLoss: 257.1396789550781\n",
      "\tEpoch: 19\tLoss: 257.1396179199219\n",
      "Completed file: merged_test_0062.csv\tTraining Losses: [257.141..257.140]\n",
      "===== Learning file: merged_test_0039.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13958740234375\n",
      "\tEpoch: 1\tLoss: 257.1395263671875\n",
      "\tEpoch: 2\tLoss: 257.13946533203125\n",
      "\tEpoch: 3\tLoss: 257.1394348144531\n",
      "\tEpoch: 4\tLoss: 257.13934326171875\n",
      "\tEpoch: 5\tLoss: 257.1392822265625\n",
      "\tEpoch: 6\tLoss: 257.1392517089844\n",
      "\tEpoch: 7\tLoss: 257.1391906738281\n",
      "\tEpoch: 8\tLoss: 257.1391296386719\n",
      "\tEpoch: 9\tLoss: 257.13909912109375\n",
      "\tEpoch: 10\tLoss: 257.1390380859375\n",
      "\tEpoch: 11\tLoss: 257.1390075683594\n",
      "\tEpoch: 12\tLoss: 257.1389465332031\n",
      "\tEpoch: 13\tLoss: 257.1388854980469\n",
      "\tEpoch: 14\tLoss: 257.1388244628906\n",
      "\tEpoch: 15\tLoss: 257.1387939453125\n",
      "\tEpoch: 16\tLoss: 257.13873291015625\n",
      "\tEpoch: 17\tLoss: 257.1387023925781\n",
      "\tEpoch: 18\tLoss: 257.1386413574219\n",
      "\tEpoch: 19\tLoss: 257.13861083984375\n",
      "Completed file: merged_test_0039.csv\tTraining Losses: [257.140..257.139]\n",
      "===== Learning file: merged_test_0040.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1385498046875\n",
      "\tEpoch: 1\tLoss: 257.1385192871094\n",
      "\tEpoch: 2\tLoss: 257.1384582519531\n",
      "\tEpoch: 3\tLoss: 257.1383972167969\n",
      "\tEpoch: 4\tLoss: 257.13836669921875\n",
      "\tEpoch: 5\tLoss: 257.1383361816406\n",
      "\tEpoch: 6\tLoss: 257.1383056640625\n",
      "\tEpoch: 7\tLoss: 257.13824462890625\n",
      "\tEpoch: 8\tLoss: 257.1382141113281\n",
      "\tEpoch: 9\tLoss: 257.1381530761719\n",
      "\tEpoch: 10\tLoss: 257.13812255859375\n",
      "\tEpoch: 11\tLoss: 257.1380920410156\n",
      "\tEpoch: 12\tLoss: 257.1380615234375\n",
      "\tEpoch: 13\tLoss: 257.13800048828125\n",
      "\tEpoch: 14\tLoss: 257.1379699707031\n",
      "\tEpoch: 15\tLoss: 257.137939453125\n",
      "\tEpoch: 16\tLoss: 257.13787841796875\n",
      "\tEpoch: 17\tLoss: 257.1378479003906\n",
      "\tEpoch: 18\tLoss: 257.1377868652344\n",
      "\tEpoch: 19\tLoss: 257.1377868652344\n",
      "Completed file: merged_test_0040.csv\tTraining Losses: [257.139..257.138]\n",
      "===== Learning file: merged_test_0035.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1377258300781\n",
      "\tEpoch: 1\tLoss: 257.1377258300781\n",
      "\tEpoch: 2\tLoss: 257.1376647949219\n",
      "\tEpoch: 3\tLoss: 257.1376037597656\n",
      "\tEpoch: 4\tLoss: 257.1375732421875\n",
      "\tEpoch: 5\tLoss: 257.1375732421875\n",
      "\tEpoch: 6\tLoss: 257.13751220703125\n",
      "\tEpoch: 7\tLoss: 257.1374816894531\n",
      "\tEpoch: 8\tLoss: 257.1374206542969\n",
      "\tEpoch: 9\tLoss: 257.13739013671875\n",
      "\tEpoch: 10\tLoss: 257.1373596191406\n",
      "\tEpoch: 11\tLoss: 257.1373291015625\n",
      "\tEpoch: 12\tLoss: 257.1372985839844\n",
      "\tEpoch: 13\tLoss: 257.13726806640625\n",
      "\tEpoch: 14\tLoss: 257.1372375488281\n",
      "\tEpoch: 15\tLoss: 257.13720703125\n",
      "\tEpoch: 16\tLoss: 257.1371765136719\n",
      "\tEpoch: 17\tLoss: 257.13714599609375\n",
      "\tEpoch: 18\tLoss: 257.1371154785156\n",
      "\tEpoch: 19\tLoss: 257.1370849609375\n",
      "Completed file: merged_test_0035.csv\tTraining Losses: [257.138..257.137]\n",
      "===== Learning file: merged_test_0026.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1370544433594\n",
      "\tEpoch: 1\tLoss: 257.13702392578125\n",
      "\tEpoch: 2\tLoss: 257.1369934082031\n",
      "\tEpoch: 3\tLoss: 257.136962890625\n",
      "\tEpoch: 4\tLoss: 257.1369323730469\n",
      "\tEpoch: 5\tLoss: 257.13690185546875\n",
      "\tEpoch: 6\tLoss: 257.1368713378906\n",
      "\tEpoch: 7\tLoss: 257.1368408203125\n",
      "\tEpoch: 8\tLoss: 257.1368103027344\n",
      "\tEpoch: 9\tLoss: 257.13677978515625\n",
      "\tEpoch: 10\tLoss: 257.13677978515625\n",
      "\tEpoch: 11\tLoss: 257.13671875\n",
      "\tEpoch: 12\tLoss: 257.1366882324219\n",
      "\tEpoch: 13\tLoss: 257.13665771484375\n",
      "\tEpoch: 14\tLoss: 257.1366271972656\n",
      "\tEpoch: 15\tLoss: 257.1366271972656\n",
      "\tEpoch: 16\tLoss: 257.1365966796875\n",
      "\tEpoch: 17\tLoss: 257.1365661621094\n",
      "\tEpoch: 18\tLoss: 257.13653564453125\n",
      "\tEpoch: 19\tLoss: 257.13653564453125\n",
      "Completed file: merged_test_0026.csv\tTraining Losses: [257.137..257.137]\n",
      "===== Learning file: merged_test_0061.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1365051269531\n",
      "\tEpoch: 1\tLoss: 257.1364440917969\n",
      "\tEpoch: 2\tLoss: 257.1364440917969\n",
      "\tEpoch: 3\tLoss: 257.13641357421875\n",
      "\tEpoch: 4\tLoss: 257.1363830566406\n",
      "\tEpoch: 5\tLoss: 257.1363525390625\n",
      "\tEpoch: 6\tLoss: 257.1363220214844\n",
      "\tEpoch: 7\tLoss: 257.13629150390625\n",
      "\tEpoch: 8\tLoss: 257.13629150390625\n",
      "\tEpoch: 9\tLoss: 257.1362609863281\n",
      "\tEpoch: 10\tLoss: 257.13623046875\n",
      "\tEpoch: 11\tLoss: 257.1361999511719\n",
      "\tEpoch: 12\tLoss: 257.1361999511719\n",
      "\tEpoch: 13\tLoss: 257.13616943359375\n",
      "\tEpoch: 14\tLoss: 257.1361389160156\n",
      "\tEpoch: 15\tLoss: 257.1361389160156\n",
      "\tEpoch: 16\tLoss: 257.1361083984375\n",
      "\tEpoch: 17\tLoss: 257.1361083984375\n",
      "\tEpoch: 18\tLoss: 257.1360778808594\n",
      "\tEpoch: 19\tLoss: 257.13604736328125\n",
      "Completed file: merged_test_0061.csv\tTraining Losses: [257.137..257.136]\n",
      "===== Learning file: merged_test_0052.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13604736328125\n",
      "\tEpoch: 1\tLoss: 257.1360168457031\n",
      "\tEpoch: 2\tLoss: 257.1359558105469\n",
      "\tEpoch: 3\tLoss: 257.1359558105469\n",
      "\tEpoch: 4\tLoss: 257.13592529296875\n",
      "\tEpoch: 5\tLoss: 257.13592529296875\n",
      "\tEpoch: 6\tLoss: 257.1358947753906\n",
      "\tEpoch: 7\tLoss: 257.1358642578125\n",
      "\tEpoch: 8\tLoss: 257.1358337402344\n",
      "\tEpoch: 9\tLoss: 257.1358337402344\n",
      "\tEpoch: 10\tLoss: 257.1358337402344\n",
      "\tEpoch: 11\tLoss: 257.13580322265625\n",
      "\tEpoch: 12\tLoss: 257.1357727050781\n",
      "\tEpoch: 13\tLoss: 257.1357727050781\n",
      "\tEpoch: 14\tLoss: 257.1357421875\n",
      "\tEpoch: 15\tLoss: 257.1357116699219\n",
      "\tEpoch: 16\tLoss: 257.1357116699219\n",
      "\tEpoch: 17\tLoss: 257.13568115234375\n",
      "\tEpoch: 18\tLoss: 257.13568115234375\n",
      "\tEpoch: 19\tLoss: 257.1356506347656\n",
      "Completed file: merged_test_0052.csv\tTraining Losses: [257.136..257.136]\n",
      "===== Learning file: merged_test_0054.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1356506347656\n",
      "\tEpoch: 1\tLoss: 257.1356201171875\n",
      "\tEpoch: 2\tLoss: 257.1356201171875\n",
      "\tEpoch: 3\tLoss: 257.1355895996094\n",
      "\tEpoch: 4\tLoss: 257.1355895996094\n",
      "\tEpoch: 5\tLoss: 257.13555908203125\n",
      "\tEpoch: 6\tLoss: 257.1355285644531\n",
      "\tEpoch: 7\tLoss: 257.1355285644531\n",
      "\tEpoch: 8\tLoss: 257.135498046875\n",
      "\tEpoch: 9\tLoss: 257.1354675292969\n",
      "\tEpoch: 10\tLoss: 257.1354675292969\n",
      "\tEpoch: 11\tLoss: 257.13543701171875\n",
      "\tEpoch: 12\tLoss: 257.1354064941406\n",
      "\tEpoch: 13\tLoss: 257.1354064941406\n",
      "\tEpoch: 14\tLoss: 257.1354064941406\n",
      "\tEpoch: 15\tLoss: 257.1353759765625\n",
      "\tEpoch: 16\tLoss: 257.1353759765625\n",
      "\tEpoch: 17\tLoss: 257.1353454589844\n",
      "\tEpoch: 18\tLoss: 257.13531494140625\n",
      "\tEpoch: 19\tLoss: 257.13531494140625\n",
      "Completed file: merged_test_0054.csv\tTraining Losses: [257.136..257.135]\n",
      "===== Learning file: merged_test_0036.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13531494140625\n",
      "\tEpoch: 1\tLoss: 257.1352844238281\n",
      "\tEpoch: 2\tLoss: 257.1352844238281\n",
      "\tEpoch: 3\tLoss: 257.13525390625\n",
      "\tEpoch: 4\tLoss: 257.13525390625\n",
      "\tEpoch: 5\tLoss: 257.1352233886719\n",
      "\tEpoch: 6\tLoss: 257.1352233886719\n",
      "\tEpoch: 7\tLoss: 257.13519287109375\n",
      "\tEpoch: 8\tLoss: 257.13519287109375\n",
      "\tEpoch: 9\tLoss: 257.13519287109375\n",
      "\tEpoch: 10\tLoss: 257.1351623535156\n",
      "\tEpoch: 11\tLoss: 257.1351318359375\n",
      "\tEpoch: 12\tLoss: 257.1351318359375\n",
      "\tEpoch: 13\tLoss: 257.1351013183594\n",
      "\tEpoch: 14\tLoss: 257.1351013183594\n",
      "\tEpoch: 15\tLoss: 257.1351013183594\n",
      "\tEpoch: 16\tLoss: 257.1351013183594\n",
      "\tEpoch: 17\tLoss: 257.13507080078125\n",
      "\tEpoch: 18\tLoss: 257.1350402832031\n",
      "\tEpoch: 19\tLoss: 257.1350402832031\n",
      "Completed file: merged_test_0036.csv\tTraining Losses: [257.135..257.135]\n",
      "===== Learning file: merged_test_0031.csv =====\n",
      "\tEpoch: 0\tLoss: 257.135009765625\n",
      "\tEpoch: 1\tLoss: 257.1349792480469\n",
      "\tEpoch: 2\tLoss: 257.1349792480469\n",
      "\tEpoch: 3\tLoss: 257.1349792480469\n",
      "\tEpoch: 4\tLoss: 257.13494873046875\n",
      "\tEpoch: 5\tLoss: 257.13494873046875\n",
      "\tEpoch: 6\tLoss: 257.13494873046875\n",
      "\tEpoch: 7\tLoss: 257.13494873046875\n",
      "\tEpoch: 8\tLoss: 257.1349182128906\n",
      "\tEpoch: 9\tLoss: 257.1349182128906\n",
      "\tEpoch: 10\tLoss: 257.1348876953125\n",
      "\tEpoch: 11\tLoss: 257.1348876953125\n",
      "\tEpoch: 12\tLoss: 257.1348876953125\n",
      "\tEpoch: 13\tLoss: 257.1348571777344\n",
      "\tEpoch: 14\tLoss: 257.1348571777344\n",
      "\tEpoch: 15\tLoss: 257.1348571777344\n",
      "\tEpoch: 16\tLoss: 257.13482666015625\n",
      "\tEpoch: 17\tLoss: 257.13482666015625\n",
      "\tEpoch: 18\tLoss: 257.1347961425781\n",
      "\tEpoch: 19\tLoss: 257.1347961425781\n",
      "Completed file: merged_test_0031.csv\tTraining Losses: [257.135..257.135]\n",
      "===== Learning file: merged_test_0047.csv =====\n",
      "\tEpoch: 0\tLoss: 257.134765625\n",
      "\tEpoch: 1\tLoss: 257.134765625\n",
      "\tEpoch: 2\tLoss: 257.134765625\n",
      "\tEpoch: 3\tLoss: 257.134765625\n",
      "\tEpoch: 4\tLoss: 257.1347351074219\n",
      "\tEpoch: 5\tLoss: 257.1347351074219\n",
      "\tEpoch: 6\tLoss: 257.13470458984375\n",
      "\tEpoch: 7\tLoss: 257.13470458984375\n",
      "\tEpoch: 8\tLoss: 257.13470458984375\n",
      "\tEpoch: 9\tLoss: 257.13470458984375\n",
      "\tEpoch: 10\tLoss: 257.1346740722656\n",
      "\tEpoch: 11\tLoss: 257.1346740722656\n",
      "\tEpoch: 12\tLoss: 257.1346740722656\n",
      "\tEpoch: 13\tLoss: 257.1346435546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch: 14\tLoss: 257.1346435546875\n",
      "\tEpoch: 15\tLoss: 257.1346435546875\n",
      "\tEpoch: 16\tLoss: 257.1346435546875\n",
      "\tEpoch: 17\tLoss: 257.1346435546875\n",
      "\tEpoch: 18\tLoss: 257.1346130371094\n",
      "\tEpoch: 19\tLoss: 257.1346130371094\n",
      "Completed file: merged_test_0047.csv\tTraining Losses: [257.135..257.135]\n",
      "===== Learning file: merged_test_0027.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13458251953125\n",
      "\tEpoch: 1\tLoss: 257.13458251953125\n",
      "\tEpoch: 2\tLoss: 257.13458251953125\n",
      "\tEpoch: 3\tLoss: 257.1345520019531\n",
      "\tEpoch: 4\tLoss: 257.1345520019531\n",
      "\tEpoch: 5\tLoss: 257.1345520019531\n",
      "\tEpoch: 6\tLoss: 257.1345520019531\n",
      "\tEpoch: 7\tLoss: 257.1344909667969\n",
      "\tEpoch: 8\tLoss: 257.1344909667969\n",
      "\tEpoch: 9\tLoss: 257.1344909667969\n",
      "\tEpoch: 10\tLoss: 257.1344909667969\n",
      "\tEpoch: 11\tLoss: 257.1344909667969\n",
      "\tEpoch: 12\tLoss: 257.13446044921875\n",
      "\tEpoch: 13\tLoss: 257.13446044921875\n",
      "\tEpoch: 14\tLoss: 257.13446044921875\n",
      "\tEpoch: 15\tLoss: 257.13446044921875\n",
      "\tEpoch: 16\tLoss: 257.1344299316406\n",
      "\tEpoch: 17\tLoss: 257.1344299316406\n",
      "\tEpoch: 18\tLoss: 257.1344299316406\n",
      "\tEpoch: 19\tLoss: 257.1344299316406\n",
      "Completed file: merged_test_0027.csv\tTraining Losses: [257.135..257.134]\n",
      "===== Learning file: merged_test_0053.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1344299316406\n",
      "\tEpoch: 1\tLoss: 257.1343994140625\n",
      "\tEpoch: 2\tLoss: 257.1343688964844\n",
      "\tEpoch: 3\tLoss: 257.1343688964844\n",
      "\tEpoch: 4\tLoss: 257.1343688964844\n",
      "\tEpoch: 5\tLoss: 257.1343688964844\n",
      "\tEpoch: 6\tLoss: 257.1343688964844\n",
      "\tEpoch: 7\tLoss: 257.1343688964844\n",
      "\tEpoch: 8\tLoss: 257.13433837890625\n",
      "\tEpoch: 9\tLoss: 257.13433837890625\n",
      "\tEpoch: 10\tLoss: 257.13433837890625\n",
      "\tEpoch: 11\tLoss: 257.1343078613281\n",
      "\tEpoch: 12\tLoss: 257.1343078613281\n",
      "\tEpoch: 13\tLoss: 257.1343078613281\n",
      "\tEpoch: 14\tLoss: 257.1343078613281\n",
      "\tEpoch: 15\tLoss: 257.1343078613281\n",
      "\tEpoch: 16\tLoss: 257.1343078613281\n",
      "\tEpoch: 17\tLoss: 257.13427734375\n",
      "\tEpoch: 18\tLoss: 257.13427734375\n",
      "\tEpoch: 19\tLoss: 257.13427734375\n",
      "Completed file: merged_test_0053.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0048.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1342468261719\n",
      "\tEpoch: 1\tLoss: 257.1342468261719\n",
      "\tEpoch: 2\tLoss: 257.1342468261719\n",
      "\tEpoch: 3\tLoss: 257.1342468261719\n",
      "\tEpoch: 4\tLoss: 257.1342468261719\n",
      "\tEpoch: 5\tLoss: 257.1342468261719\n",
      "\tEpoch: 6\tLoss: 257.13421630859375\n",
      "\tEpoch: 7\tLoss: 257.13421630859375\n",
      "\tEpoch: 8\tLoss: 257.13421630859375\n",
      "\tEpoch: 9\tLoss: 257.13421630859375\n",
      "\tEpoch: 10\tLoss: 257.13421630859375\n",
      "\tEpoch: 11\tLoss: 257.1341857910156\n",
      "\tEpoch: 12\tLoss: 257.1341857910156\n",
      "\tEpoch: 13\tLoss: 257.1341857910156\n",
      "\tEpoch: 14\tLoss: 257.1341857910156\n",
      "\tEpoch: 15\tLoss: 257.1341857910156\n",
      "\tEpoch: 16\tLoss: 257.1341552734375\n",
      "\tEpoch: 17\tLoss: 257.1341552734375\n",
      "\tEpoch: 18\tLoss: 257.1341552734375\n",
      "\tEpoch: 19\tLoss: 257.1341552734375\n",
      "Completed file: merged_test_0048.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0051.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1341552734375\n",
      "\tEpoch: 1\tLoss: 257.1341552734375\n",
      "\tEpoch: 2\tLoss: 257.1341247558594\n",
      "\tEpoch: 3\tLoss: 257.1341247558594\n",
      "\tEpoch: 4\tLoss: 257.1341247558594\n",
      "\tEpoch: 5\tLoss: 257.1341247558594\n",
      "\tEpoch: 6\tLoss: 257.13409423828125\n",
      "\tEpoch: 7\tLoss: 257.13409423828125\n",
      "\tEpoch: 8\tLoss: 257.13409423828125\n",
      "\tEpoch: 9\tLoss: 257.13409423828125\n",
      "\tEpoch: 10\tLoss: 257.13409423828125\n",
      "\tEpoch: 11\tLoss: 257.13409423828125\n",
      "\tEpoch: 12\tLoss: 257.13409423828125\n",
      "\tEpoch: 13\tLoss: 257.13409423828125\n",
      "\tEpoch: 14\tLoss: 257.13409423828125\n",
      "\tEpoch: 15\tLoss: 257.1340637207031\n",
      "\tEpoch: 16\tLoss: 257.1340637207031\n",
      "\tEpoch: 17\tLoss: 257.1340637207031\n",
      "\tEpoch: 18\tLoss: 257.1340026855469\n",
      "\tEpoch: 19\tLoss: 257.1340026855469\n",
      "Completed file: merged_test_0051.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0042.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1340026855469\n",
      "\tEpoch: 1\tLoss: 257.1340026855469\n",
      "\tEpoch: 2\tLoss: 257.1340026855469\n",
      "\tEpoch: 3\tLoss: 257.1340026855469\n",
      "\tEpoch: 4\tLoss: 257.1340026855469\n",
      "\tEpoch: 5\tLoss: 257.1340026855469\n",
      "\tEpoch: 6\tLoss: 257.13397216796875\n",
      "\tEpoch: 7\tLoss: 257.13397216796875\n",
      "\tEpoch: 8\tLoss: 257.13397216796875\n",
      "\tEpoch: 9\tLoss: 257.13397216796875\n",
      "\tEpoch: 10\tLoss: 257.13397216796875\n",
      "\tEpoch: 11\tLoss: 257.13397216796875\n",
      "\tEpoch: 12\tLoss: 257.13397216796875\n",
      "\tEpoch: 13\tLoss: 257.13397216796875\n",
      "\tEpoch: 14\tLoss: 257.13397216796875\n",
      "\tEpoch: 15\tLoss: 257.1339416503906\n",
      "\tEpoch: 16\tLoss: 257.1339416503906\n",
      "\tEpoch: 17\tLoss: 257.1339416503906\n",
      "\tEpoch: 18\tLoss: 257.1339416503906\n",
      "\tEpoch: 19\tLoss: 257.1339416503906\n",
      "Completed file: merged_test_0042.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0059.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1339416503906\n",
      "\tEpoch: 1\tLoss: 257.1339416503906\n",
      "\tEpoch: 2\tLoss: 257.1339111328125\n",
      "\tEpoch: 3\tLoss: 257.1339111328125\n",
      "\tEpoch: 4\tLoss: 257.1339111328125\n",
      "\tEpoch: 5\tLoss: 257.1339111328125\n",
      "\tEpoch: 6\tLoss: 257.1339111328125\n",
      "\tEpoch: 7\tLoss: 257.1339111328125\n",
      "\tEpoch: 8\tLoss: 257.1339111328125\n",
      "\tEpoch: 9\tLoss: 257.1339111328125\n",
      "\tEpoch: 10\tLoss: 257.1339111328125\n",
      "\tEpoch: 11\tLoss: 257.1338806152344\n",
      "\tEpoch: 12\tLoss: 257.1338806152344\n",
      "\tEpoch: 13\tLoss: 257.1338806152344\n",
      "\tEpoch: 14\tLoss: 257.1338806152344\n",
      "\tEpoch: 15\tLoss: 257.1338806152344\n",
      "\tEpoch: 16\tLoss: 257.1338806152344\n",
      "\tEpoch: 17\tLoss: 257.1338806152344\n",
      "\tEpoch: 18\tLoss: 257.13385009765625\n",
      "\tEpoch: 19\tLoss: 257.13385009765625\n",
      "Completed file: merged_test_0059.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0034.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13385009765625\n",
      "\tEpoch: 1\tLoss: 257.13385009765625\n",
      "\tEpoch: 2\tLoss: 257.13385009765625\n",
      "\tEpoch: 3\tLoss: 257.13385009765625\n",
      "\tEpoch: 4\tLoss: 257.13385009765625\n",
      "\tEpoch: 5\tLoss: 257.13385009765625\n",
      "\tEpoch: 6\tLoss: 257.1338195800781\n",
      "\tEpoch: 7\tLoss: 257.1338195800781\n",
      "\tEpoch: 8\tLoss: 257.1338195800781\n",
      "\tEpoch: 9\tLoss: 257.1338195800781\n",
      "\tEpoch: 10\tLoss: 257.1338195800781\n",
      "\tEpoch: 11\tLoss: 257.1338195800781\n",
      "\tEpoch: 12\tLoss: 257.1338195800781\n",
      "\tEpoch: 13\tLoss: 257.1338195800781\n",
      "\tEpoch: 14\tLoss: 257.1338195800781\n",
      "\tEpoch: 15\tLoss: 257.1338195800781\n",
      "\tEpoch: 16\tLoss: 257.1337890625\n",
      "\tEpoch: 17\tLoss: 257.1337890625\n",
      "\tEpoch: 18\tLoss: 257.1337890625\n",
      "\tEpoch: 19\tLoss: 257.1337890625\n",
      "Completed file: merged_test_0034.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0056.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1337890625\n",
      "\tEpoch: 1\tLoss: 257.1337890625\n",
      "\tEpoch: 2\tLoss: 257.1337890625\n",
      "\tEpoch: 3\tLoss: 257.1337890625\n",
      "\tEpoch: 4\tLoss: 257.1337890625\n",
      "\tEpoch: 5\tLoss: 257.1337890625\n",
      "\tEpoch: 6\tLoss: 257.1337585449219\n",
      "\tEpoch: 7\tLoss: 257.1337585449219\n",
      "\tEpoch: 8\tLoss: 257.1337585449219\n",
      "\tEpoch: 9\tLoss: 257.1337585449219\n",
      "\tEpoch: 10\tLoss: 257.1337585449219\n",
      "\tEpoch: 11\tLoss: 257.13372802734375\n",
      "\tEpoch: 12\tLoss: 257.13372802734375\n",
      "\tEpoch: 13\tLoss: 257.13372802734375\n",
      "\tEpoch: 14\tLoss: 257.13372802734375\n",
      "\tEpoch: 15\tLoss: 257.13372802734375\n",
      "\tEpoch: 16\tLoss: 257.13372802734375\n",
      "\tEpoch: 17\tLoss: 257.13372802734375\n",
      "\tEpoch: 18\tLoss: 257.13372802734375\n",
      "\tEpoch: 19\tLoss: 257.13372802734375\n",
      "Completed file: merged_test_0056.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0030.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13372802734375\n",
      "\tEpoch: 1\tLoss: 257.13372802734375\n",
      "\tEpoch: 2\tLoss: 257.13372802734375\n",
      "\tEpoch: 3\tLoss: 257.13372802734375\n",
      "\tEpoch: 4\tLoss: 257.13372802734375\n",
      "\tEpoch: 5\tLoss: 257.13372802734375\n",
      "\tEpoch: 6\tLoss: 257.1336975097656\n",
      "\tEpoch: 7\tLoss: 257.1336975097656\n",
      "\tEpoch: 8\tLoss: 257.1336975097656\n",
      "\tEpoch: 9\tLoss: 257.1336975097656\n",
      "\tEpoch: 10\tLoss: 257.1336975097656\n",
      "\tEpoch: 11\tLoss: 257.1336975097656\n",
      "\tEpoch: 12\tLoss: 257.1336975097656\n",
      "\tEpoch: 13\tLoss: 257.1336975097656\n",
      "\tEpoch: 14\tLoss: 257.1336975097656\n",
      "\tEpoch: 15\tLoss: 257.1336975097656\n",
      "\tEpoch: 16\tLoss: 257.1336975097656\n",
      "\tEpoch: 17\tLoss: 257.1336669921875\n",
      "\tEpoch: 18\tLoss: 257.1336669921875\n",
      "\tEpoch: 19\tLoss: 257.1336669921875\n",
      "Completed file: merged_test_0030.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0032.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1336669921875\n",
      "\tEpoch: 1\tLoss: 257.1336669921875\n",
      "\tEpoch: 2\tLoss: 257.1336669921875\n",
      "\tEpoch: 3\tLoss: 257.1336669921875\n",
      "\tEpoch: 4\tLoss: 257.1336669921875\n",
      "\tEpoch: 5\tLoss: 257.1336669921875\n",
      "\tEpoch: 6\tLoss: 257.1336669921875\n",
      "\tEpoch: 7\tLoss: 257.1336669921875\n",
      "\tEpoch: 8\tLoss: 257.1336669921875\n",
      "\tEpoch: 9\tLoss: 257.1336669921875\n",
      "\tEpoch: 10\tLoss: 257.1336669921875\n",
      "\tEpoch: 11\tLoss: 257.1336669921875\n",
      "\tEpoch: 12\tLoss: 257.1336669921875\n",
      "\tEpoch: 13\tLoss: 257.1336669921875\n",
      "\tEpoch: 14\tLoss: 257.1336669921875\n",
      "\tEpoch: 15\tLoss: 257.1336364746094\n",
      "\tEpoch: 16\tLoss: 257.1336364746094\n",
      "\tEpoch: 17\tLoss: 257.1336364746094\n",
      "\tEpoch: 18\tLoss: 257.1336364746094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch: 19\tLoss: 257.1336364746094\n",
      "Completed file: merged_test_0032.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0060.csv =====\n",
      "\tEpoch: 0\tLoss: 257.1336364746094\n",
      "\tEpoch: 1\tLoss: 257.1336364746094\n",
      "\tEpoch: 2\tLoss: 257.1336364746094\n",
      "\tEpoch: 3\tLoss: 257.1336364746094\n",
      "\tEpoch: 4\tLoss: 257.1336364746094\n",
      "\tEpoch: 5\tLoss: 257.1336364746094\n",
      "\tEpoch: 6\tLoss: 257.1336364746094\n",
      "\tEpoch: 7\tLoss: 257.1336364746094\n",
      "\tEpoch: 8\tLoss: 257.1336364746094\n",
      "\tEpoch: 9\tLoss: 257.1336364746094\n",
      "\tEpoch: 10\tLoss: 257.13360595703125\n",
      "\tEpoch: 11\tLoss: 257.13360595703125\n",
      "\tEpoch: 12\tLoss: 257.13360595703125\n",
      "\tEpoch: 13\tLoss: 257.13360595703125\n",
      "\tEpoch: 14\tLoss: 257.13360595703125\n",
      "\tEpoch: 15\tLoss: 257.13360595703125\n",
      "\tEpoch: 16\tLoss: 257.13360595703125\n",
      "\tEpoch: 17\tLoss: 257.13360595703125\n",
      "\tEpoch: 18\tLoss: 257.13360595703125\n",
      "\tEpoch: 19\tLoss: 257.13360595703125\n",
      "Completed file: merged_test_0060.csv\tTraining Losses: [257.134..257.134]\n",
      "===== Learning file: merged_test_0029.csv =====\n",
      "\tEpoch: 0\tLoss: 257.13360595703125\n",
      "\tEpoch: 1\tLoss: 257.13360595703125\n",
      "\tEpoch: 2\tLoss: 257.13360595703125\n",
      "\tEpoch: 3\tLoss: 257.13360595703125\n",
      "\tEpoch: 4\tLoss: 257.13360595703125\n",
      "\tEpoch: 5\tLoss: 257.1335754394531\n",
      "\tEpoch: 6\tLoss: 257.1335754394531\n",
      "\tEpoch: 7\tLoss: 257.1335754394531\n",
      "\tEpoch: 8\tLoss: 257.1335754394531\n",
      "\tEpoch: 9\tLoss: 257.1335754394531\n",
      "\tEpoch: 10\tLoss: 257.1335754394531\n",
      "\tEpoch: 11\tLoss: 257.1335754394531\n",
      "\tEpoch: 12\tLoss: 257.1335754394531\n",
      "\tEpoch: 13\tLoss: 257.1335754394531\n",
      "\tEpoch: 14\tLoss: 257.1335754394531\n",
      "\tEpoch: 15\tLoss: 257.1335754394531\n",
      "\tEpoch: 16\tLoss: 257.1335754394531\n",
      "\tEpoch: 17\tLoss: 257.1335754394531\n",
      "\tEpoch: 18\tLoss: 257.1335754394531\n",
      "\tEpoch: 19\tLoss: 257.1335754394531\n",
      "Completed file: merged_test_0029.csv\tTraining Losses: [257.134..257.134]\n",
      "===== ========== =====\n",
      "Saved model in file: model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 20\n",
    "\n",
    "total_training_losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for filename in glob.glob(\"*.csv\"):\n",
    "        print(\"===== Learning file: {} =====\".format(filename))\n",
    "        \n",
    "        values = getValuesFromFile(filename)\n",
    "        jws = createJumpingWindows(values)\n",
    "        \n",
    "        training_losses_per_file = []\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            for jw in jws.getAllWindows():\n",
    "                matrix = shapeMatrix(jw,1,30)\n",
    "                sess.run(train, feed_dict={X:matrix})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X:matrix})\n",
    "            training_losses_per_file.append(training_loss)\n",
    "            \n",
    "            print(\"\\tEpoch: {}\\tLoss: {}\".format(epoch, training_loss))\n",
    "        \n",
    "        print(\n",
    "            \"Completed file: {}\\tTraining Losses: [{:0.3f}..{:0.3f}]\".format(\n",
    "                filename,\n",
    "                training_losses_per_file[0],\n",
    "                training_losses_per_file[-1]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_training_losses.append(training_losses_per_file[:])\n",
    "        \n",
    "    model_filename = \"model.ckpt\"\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, model_filename)\n",
    "    print(\"===== ========== =====\\nSaved model in file: {}\".format(model_filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Losses')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot = []\n",
    "for training_loss_per_file in total_training_losses:\n",
    "    avg_loss = sum(training_loss_per_file) / len(training_loss_per_file)\n",
    "    to_plot.append(avg_loss)\n",
    "    \n",
    "plt.plot(to_plot, 'r--')\n",
    "plt.title('Avg Loss Per Trained File')\n",
    "plt.xlabel('Number of files trained')\n",
    "plt.ylabel('Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 13:29:36.557221 140421599201088 deprecation.py:323] From /home/steve/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULT: =====\n",
      "Avg RSME for segments in the new test: 257.13358\n",
      "===== ======= =====\n"
     ]
    }
   ],
   "source": [
    "# Evaluating\n",
    "\n",
    "# Craete a list of random numbers representing a test\n",
    "import random\n",
    "new_test_values = []\n",
    "for x in range(360):\n",
    "    new_test_values.append(random.uniform(-100,100))\n",
    "\n",
    "jws = createJumpingWindows(new_test_values)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_filename)\n",
    "    losses_per_segment = []\n",
    "    for jw in jws.getAllWindows():\n",
    "        matrix = shapeMatrix(jw,1,30)\n",
    "        segment_loss = loss.eval(feed_dict={X:matrix})\n",
    "        losses_per_segment.append(segment_loss)\n",
    "    \n",
    "    print(\n",
    "        \"\\n===== RESULT: =====\\nAvg RSME for segments in the new test: {:0.5f}\\n===== ======= =====\".format(\n",
    "            sum(losses_per_segment) / len(losses_per_segment)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
